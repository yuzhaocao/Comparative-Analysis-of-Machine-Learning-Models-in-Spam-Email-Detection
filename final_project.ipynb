{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49da2419-9a43-4502-a316-bdd095d1d62f",
   "metadata": {},
   "source": [
    "# ECS750P MSc Project - Spam Email Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36efa5a-1d2c-49cd-ae32-2f7d0ca1e6d1",
   "metadata": {},
   "source": [
    "#### Imports the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0a2496-8d5f-496b-b911-42e0cf429dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caac6ac-f5eb-4818-8ecb-05b21fd475f4",
   "metadata": {},
   "source": [
    "#### Function to load one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7590cd65-294b-4a7c-9285-5ad669ebc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the entire message as a string, and removes the '\\n' and '\\r'\n",
    "def load_one_file(filename):\n",
    "    x = \"\"\n",
    "    with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('\\r')\n",
    "            x += line\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6f2fa-6fd2-4608-af47-65cff06312eb",
   "metadata": {},
   "source": [
    "#### Function to load all files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c99aa9-eadd-4a29-828b-90881d41128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all files in the specified folder and load the data\n",
    "def load_files_from_dir(rootdir):\n",
    "    x = []\n",
    "    list = os.listdir(rootdir)\n",
    "    for i in range(0, len(list)):\n",
    "        path = os.path.join(rootdir, list[i])\n",
    "        if os.path.isfile(path):\n",
    "            v = load_one_file(path)\n",
    "            x.append(v)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19083d2f-3fe2-4472-ab58-73091153c2c7",
   "metadata": {},
   "source": [
    "#### Function to load all the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ac7e18-7dba-4319-bf05-712c51f3b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder where the data stored is located, stores normal emails inn ham and spam emails in spam\n",
    "def load_all_files():\n",
    "    ham = []\n",
    "    spam = []\n",
    "    # load from the first folder enron1\n",
    "    for i in range(1, 2): \n",
    "        path = \"data/enron%d/ham/\" % i\n",
    "        print(\"Load %s\" % path)\n",
    "        ham += load_files_from_dir(path)\n",
    "        path = \"data/enron%d/spam/\" % i\n",
    "        print(\"Load %s\" % path)\n",
    "        spam += load_files_from_dir(path)\n",
    "    return ham, spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f331b5-b6b6-4e21-a2de-ae6c952b21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data/enron1/ham/\n",
      "Load data/enron1/spam/\n"
     ]
    }
   ],
   "source": [
    "ham, spam = load_all_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee26f2-acec-44ad-b99b-3f073929fdb2",
   "metadata": {},
   "source": [
    "#### Use bag-of-words modelling to vectorise email samples, ham with label 0, spam with label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f59887-fd97-4ce8-8643-1c3a34eb5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_by_wordbag(ham, spam):\n",
    "    x = ham + spam\n",
    "    y = [0] * len(ham) + [1] * len(spam)\n",
    "    vectorizer = CountVectorizer(\n",
    "        decode_error = 'ignore',\n",
    "        strip_accents = 'ascii',\n",
    "        max_features = 5000,\n",
    "        stop_words = 'english',\n",
    "        max_df = 1.0,\n",
    "        min_df = 1)\n",
    "    x = vectorizer.fit_transform(x)\n",
    "    x = x.toarray()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea76abb-3026-48ea-87fc-a7dc8018475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_features_by_wordbag(ham, spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222346d3-217e-4713-930e-67bd05314724",
   "metadata": {},
   "source": [
    "#### Split into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a02119-be85-40dd-961e-f6b3d6bb4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% train and 40% test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677ce08-210d-4ce2-bbd4-b6dbe4bfef4f",
   "metadata": {},
   "source": [
    "#### Building a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717c8702-4bbc-495c-b544-3d31e5234110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"Naive Bayes Model\")\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    final_scores = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision =  %f Recall = %f F1 Score = %f\" % final_scores[:3])\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9270c13d-41ec-414d-9a0e-5ce2e8b22a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model\n",
      "Accuracy Score:  0.9545674238762687\n",
      "Precision =  0.955284 Recall = 0.954567 F1 Score = 0.954800\n",
      "[[1405   58]\n",
      " [  36  570]]\n"
     ]
    }
   ],
   "source": [
    "nb_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c91885-cbf1-4f3f-89ce-40bf862a9993",
   "metadata": {},
   "source": [
    "#### The accuracy was 95.46% and the accuracy of the evaluation results is shown in the table below\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4c526-3aa0-46b8-bc38-cf0d4b0677ed",
   "metadata": {},
   "source": [
    "|   | Related | Unrelated |\n",
    "|:--------:|:--------:|:--------:|\n",
    "|  Detected   |  1405   |  58   |\n",
    "|  Undetected   |  36   |  570   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305b604-e70c-4d58-94e9-528315ef3762",
   "metadata": {},
   "source": [
    "#### Building a Support Vector Machine (SVM) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349d8f63-f2ab-431f-acfb-7077a18a713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"SVM Model\")\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    final_scores = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision =  %f Recall = %f F1 Score = %f\" % final_scores[:3])\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40eda39f-a876-4c8c-b388-a06bf24d3098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model\n",
      "Accuracy Score:  0.9647172547124214\n",
      "Precision =  0.965454 Recall = 0.964717 F1 Score = 0.964922\n",
      "[[1414   49]\n",
      " [  24  582]]\n"
     ]
    }
   ],
   "source": [
    "svm_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9651a-aa48-4dae-b6c4-aaeaa0f35b59",
   "metadata": {},
   "source": [
    "#### Building a K-Nearest Neighbours (KNN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62ba3af-b52b-4d3b-a47a-58e0424ec2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"KNN Model\")\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    final_scores = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision =  %f Recall = %f F1 Score = %f\" % final_scores[:3])\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845407cd-2bc1-4af9-9fe3-867a380207ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model\n",
      "Accuracy Score:  0.8032866118898019\n",
      "Precision =  0.871162 Recall = 0.803287 F1 Score = 0.812049\n",
      "[[1075  388]\n",
      " [  19  587]]\n"
     ]
    }
   ],
   "source": [
    "knn_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939abf53-a634-48c3-9d9f-ca2a91223df9",
   "metadata": {},
   "source": [
    "#### Building a Logistic Regression (LR) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7c527c-b06b-4a87-9527-bb46c1618cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"LR Model\")\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    final_scores = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision =  %f Recall = %f F1 Score = %f\" % final_scores[:3])\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d1e7e0-8069-4c93-93b6-492850824926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Model\n",
      "Accuracy Score:  0.9777670372160464\n",
      "Precision =  0.978323 Recall = 0.977767 F1 Score = 0.977891\n",
      "[[1428   35]\n",
      " [  11  595]]\n"
     ]
    }
   ],
   "source": [
    "lr_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcee77-f4ee-4dc5-87a8-f4bdfc75b95c",
   "metadata": {},
   "source": [
    "#### Building a Deep Neural Network (DNN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d910e6-05cf-4aa9-979b-813e3be15823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(x_train, x_test, y_train, y_test):\n",
    "    print(\"DNN Model\")\n",
    "    # Building deep neural network\n",
    "    clf = MLPClassifier(solver='lbfgs',\n",
    "                        alpha=1e-5,\n",
    "                        hidden_layer_sizes=(5, 2),\n",
    "                        random_state=1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy Score: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    final_scores = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision =  %f Recall = %f F1 Score = %f\" % final_scores[:3])\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd56c50-b78b-4b09-9120-a7d2216a0c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Model\n",
      "Accuracy Score:  0.9792170130497825\n",
      "Precision =  0.979188 Recall = 0.979217 F1 Score = 0.979140\n",
      "[[1449   14]\n",
      " [  29  577]]\n"
     ]
    }
   ],
   "source": [
    "dnn_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540755e8-a3c8-481d-86ac-f11e5ad280b5",
   "metadata": {},
   "source": [
    "#### Apply TF-IDF to refines the representation by weighing terms based on their significance in the document relative to the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63f3f8a-eba5-411b-8c99-0ee26a413ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_by_wordbag_tfidf(ham, spam):\n",
    "    x = ham + spam\n",
    "    y = [0] * len(ham) + [1] * len(spam)\n",
    "    vectorizer = CountVectorizer(binary=False,\n",
    "                                 decode_error='ignore',\n",
    "                                 strip_accents='ascii',\n",
    "                                 max_features=5000,\n",
    "                                 stop_words='english',\n",
    "                                 max_df=1.0,\n",
    "                                 min_df=1)\n",
    "    x = vectorizer.fit_transform(x)\n",
    "    x = x.toarray()\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf = transformer.fit_transform(x)\n",
    "    x = tfidf.toarray()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bb84ab3-c0be-4cec-87eb-6a14ac459779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the word bag and get a new train and test sets\n",
    "x, y = get_features_by_wordbag_tfidf(ham, spam)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f5fc23-4bbe-4aad-a0c3-bda8e98af160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model\n",
      "Accuracy Score:  0.958434026099565\n",
      "Precision =  0.958245 Recall = 0.958434 F1 Score = 0.958183\n",
      "[[1432   31]\n",
      " [  55  551]]\n",
      "SVM Model\n",
      "Accuracy Score:  0.9903334944417593\n",
      "Precision =  0.990333 Recall = 0.990333 F1 Score = 0.990333\n",
      "[[1453   10]\n",
      " [  10  596]]\n",
      "KNN Model\n",
      "Accuracy Score:  0.9647172547124214\n",
      "Precision =  0.964662 Recall = 0.964717 F1 Score = 0.964458\n",
      "[[1441   22]\n",
      " [  51  555]]\n",
      "LR Model\n",
      "Accuracy Score:  0.9840502658289029\n",
      "Precision =  0.984023 Recall = 0.984050 F1 Score = 0.984023\n",
      "[[1450   13]\n",
      " [  20  586]]\n",
      "DNN Model\n",
      "Accuracy Score:  0.9821169647172547\n",
      "Precision =  0.982177 Recall = 0.982117 F1 Score = 0.982023\n",
      "[[1455    8]\n",
      " [  29  577]]\n"
     ]
    }
   ],
   "source": [
    "nb_model(x_train, x_test, y_train, y_test)\n",
    "svm_model(x_train, x_test, y_train, y_test)\n",
    "knn_model(x_train, x_test, y_train, y_test)\n",
    "lr_model(x_train, x_test, y_train, y_test)\n",
    "dnn_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2629ce-d4d6-456c-9cd8-b64375fc155e",
   "metadata": {},
   "source": [
    "#### Table I: PERFORMANCE METRICS OF DIFFERENT MODELS USING ONLY BoW\r\n",
    "\r\n",
    "| Model              | Accuracy (%) | Precision (%) | Recall (%) | F1 Score (%) |\r\n",
    "|--------------------|--------------|---------------|------------|--------------|\r\n",
    "| Naive Bayes        | 95.46        | 95.53         | 95.46      | 95.48        |\r\n",
    "| SVM                | 96.47        | 96.55         | 96.47      | 96.49        |\r\n",
    "| KNN                | 80.33        | 87.12         | 80.33      | 81.20        |\r\n",
    "| Logistic Regression| 97.78        | 97.83         | 97.78      | 97.79        |\r\n",
    "| DNN                | 97.92        | 97.92         | 97.92      | 97.91     | 98.20        |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9389d1-24ab-4d6a-ad45-6126f66a6f1c",
   "metadata": {},
   "source": [
    "#### Table II: PERFORMANCE METRICS OF DIFFERENT MODELS USING BOW INTEGRATED WITH TF-IDF\n",
    "\n",
    "| Model              | Accuracy (%) | Precision (%) | Recall (%) | F1 Score (%) |\n",
    "|--------------------|--------------|---------------|------------|--------------|\n",
    "| Naive Bayes        | 95.84        | 95.82         | 95.84      | 95.82        |\n",
    "| SVM                | 99.03        | 99.03         | 99.03      | 99.03        |\n",
    "| KNN                | 96.47        | 96.47         | 96.47      | 96.45        |\n",
    "| Logistic Regression| 98.41        | 98.40         | 98.41      | 98.40        |\n",
    "| DNN                | 98.21        | 98.22         | 98.21      | 98.20        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
